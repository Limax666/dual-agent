"""
è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)æ¨¡å—

ä½¿ç”¨Whisper APIæˆ–æœ¬åœ°Whisperæ¨¡å‹å®ç°å®æ—¶è¯­éŸ³è½¬æ–‡æœ¬ï¼Œæ”¯æŒæµå¼è¾“å…¥ä»¥å®ç°è¾¹å¬è¾¹æƒ³
"""

import asyncio
import io
import os
import time
import wave
import tempfile
import numpy as np
import torch
from typing import Dict, List, Optional, Union, Callable, Tuple, Any
from pathlib import Path
from enum import Enum, auto
from typing import Optional, Dict, Any
import os
import torch
from faster_whisper import WhisperModel
# from volcengine.asr_service import AsrService

# å°è¯•å¯¼å…¥OpenAIåº“ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨faster-whisperæœ¬åœ°æ¨¡å‹
try:
    import openai
    OPENAI_API_AVAILABLE = True
except ImportError:
    OPENAI_API_AVAILABLE = False

# å°è¯•å¯¼å…¥faster-whisperåº“ï¼Œç”¨äºæœ¬åœ°å¤„ç†
try:
    from faster_whisper import WhisperModel
    FASTER_WHISPER_AVAILABLE = True
except ImportError:
    FASTER_WHISPER_AVAILABLE = False


class ASRProvider(Enum):
    """ASRæä¾›å•†æšä¸¾"""
    LOCAL = auto()
    OPENAI = auto()
    DOUBAO = auto()
    SILICONFLOW = auto()

class StreamingASR:
    """æµå¼ASRå¤„ç†ï¼Œæ”¯æŒæœ¬åœ°å’ŒAPI"""
    def __init__(
        self,
        provider: ASRProvider = ASRProvider.DOUBAO,
        model_size_or_name: str = "base",
        language: str = "zh",
        api_key: Optional[str] = None
    ):
        self.provider = provider
        self.language = language
        self.model_size_or_name = model_size_or_name

        if self.provider == ASRProvider.LOCAL:
            self.model = WhisperModel(model_size_or_name, device="cpu", compute_type="int8")
        elif self.provider == ASRProvider.OPENAI:
            from openai import AsyncOpenAI
            self.client = AsyncOpenAI(api_key=api_key or os.environ.get("OPENAI_API_KEY"))
        elif self.provider == ASRProvider.DOUBAO:
            if not api_key:
                if os.environ.get("VOLC_ACCESS_KEY_ID") and os.environ.get("VOLC_SECRET_ACCESS_KEY"):
                    self.access_key_id = os.environ["VOLC_ACCESS_KEY_ID"]
                    self.secret_access_key = os.environ["VOLC_SECRET_ACCESS_KEY"]
                else:
                    raise ValueError("æœªæä¾›Doubao APIå¯†é’¥ï¼Œè¯·è®¾ç½®VOLC_ACCESS_KEY_IDå’ŒVOLC_SECRET_ACCESS_KEYç¯å¢ƒå˜é‡")
            self.asr_service = AsrService(
                access_key_id=self.access_key_id,
                secret_access_key=self.secret_access_key
            )
        elif self.provider == ASRProvider.SILICONFLOW:
            self.api_key = api_key or os.environ.get("SILICONFLOW_API_KEY")
            if not self.api_key:
                raise ValueError("æœªæä¾›Siliconflow APIå¯†é’¥ï¼Œè¯·è®¾ç½®SILICONFLOW_API_KEYç¯å¢ƒå˜é‡")
            self.base_url = "https://api.siliconflow.cn/v1"

    async def process_audio_segment(self, audio_tensor: torch.Tensor) -> Dict[str, Any]:
        """å¤„ç†ä¸€ä¸ªéŸ³é¢‘ç‰‡æ®µ"""
        if self.provider == ASRProvider.LOCAL:
            # This part needs to be implemented based on how you want to handle local transcription
            return {"text": "Local transcription not implemented yet."}
        elif self.provider == ASRProvider.OPENAI:
             # This part needs to be implemented based on how you want to handle OpenAI transcription
            return {"text": "OpenAI transcription not implemented yet."}
        elif self.provider == ASRProvider.DOUBAO:
            return await self._transcribe_with_doubao(audio_tensor)
        elif self.provider == ASRProvider.SILICONFLOW:
            return await self._transcribe_with_siliconflow(audio_tensor)
        else:
            raise ValueError(f"Unsupported ASR provider: {self.provider}")

    async def _transcribe_with_doubao(self, audio_tensor: torch.Tensor) -> Dict[str, Any]:
        """ä½¿ç”¨Doubao ASR"""
        try:
            audio_bytes = audio_tensor.numpy().tobytes()
            resp = self.asr_service.recognize(
                audio_bytes,
                self.language,
                self.model_size_or_name
            )
            return {"text": resp.result}
        except Exception as e:
            print(f"Doubao ASRé”™è¯¯: {str(e)}")
            return {"text": ""}

    async def _transcribe_with_siliconflow(self, audio_tensor: torch.Tensor) -> Dict[str, Any]:
        """ä½¿ç”¨Siliconflow ASR (FunAudioLLM/SenseVoiceSmall)"""
        try:
            print(f"ğŸ”„ å¼€å§‹Siliconflow ASRè½¬å½•ï¼ŒéŸ³é¢‘é•¿åº¦: {len(audio_tensor)} æ ·æœ¬")
            
            from openai import AsyncOpenAI
            import io
            import wave
            
            # åˆ›å»ºSiliconflowå®¢æˆ·ç«¯
            client = AsyncOpenAI(
                base_url=self.base_url,
                api_key=self.api_key
            )
            
            print(f"âœ… Siliconflowå®¢æˆ·ç«¯å·²åˆ›å»ºï¼ŒAPI URL: {self.base_url}")
            
            # å°†torch tensorè½¬æ¢ä¸ºwavæ ¼å¼çš„å­—èŠ‚æµ
            audio_numpy = audio_tensor.numpy()
            audio_bytes = io.BytesIO()
            
            print(f"ğŸµ éŸ³é¢‘æ•°æ®èŒƒå›´: [{audio_numpy.min():.3f}, {audio_numpy.max():.3f}]")
            
            with wave.open(audio_bytes, 'wb') as wav_file:
                wav_file.setnchannels(1)  # å•å£°é“
                wav_file.setsampwidth(2)  # 16ä½
                wav_file.setframerate(16000)  # 16kHzé‡‡æ ·ç‡
                wav_file.writeframes((audio_numpy * 32767).astype(np.int16).tobytes())
            
            audio_bytes.seek(0)
            audio_data = audio_bytes.read()
            print(f"ğŸ“ WAVæ–‡ä»¶å¤§å°: {len(audio_data)} å­—èŠ‚")
            
            # ä½¿ç”¨FunAudioLLM/SenseVoiceSmallæ¨¡å‹è¿›è¡Œè½¬å½•
            print("ğŸš€ æ­£åœ¨è°ƒç”¨Siliconflow ASR API...")
            transcription = await client.audio.transcriptions.create(
                model="FunAudioLLM/SenseVoiceSmall",
                file=("audio.wav", audio_data, "audio/wav"),
                language=self.language,  # æŒ‡å®šè¯­è¨€å¯ä»¥æé«˜å‡†ç¡®ç‡
                prompt="è¿™æ˜¯ä¸€æ®µå¯¹è¯å½•éŸ³"  # æä¾›ä¸Šä¸‹æ–‡
            )
            
            result_text = transcription.text.strip()
            print(f"âœ… ASRè½¬å½•æˆåŠŸ: '{result_text}'")
            
            return {"text": result_text}
            
        except Exception as e:
            print(f"âŒ Siliconflow ASRé”™è¯¯: {str(e)}")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            return {"text": "", "error": str(e)}
