"""
æ··åˆæ€è€ƒå¼•æ“æ¨¡å—

å®ç°å¿«æ…¢æ€è€ƒç»“åˆçš„è¾¹å¬è¾¹æƒ³èƒ½åŠ›ï¼Œé€šè¿‡å¿«æ€è€ƒè·¯å¾„æä¾›å®æ—¶åé¦ˆï¼Œ
åŒæ—¶é€šè¿‡æ…¢æ€è€ƒè·¯å¾„è¿›è¡Œæ·±åº¦åˆ†æä¸å¤æ‚æ¨ç†
"""

import asyncio
import json
import time
import uuid
from typing import Dict, List, Optional, Union, Any, Callable, Tuple
from enum import Enum, auto
import os
import aiohttp
from openai import AsyncOpenAI

# å°è¯•å¯¼å…¥Anthropicåº“
try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False


class ThinkingMode(Enum):
    """æ€è€ƒæ¨¡å¼æšä¸¾"""
    FAST = auto()   # å¿«æ€è€ƒæ¨¡å¼ï¼Œä½å»¶è¿Ÿ
    DEEP = auto()   # æ·±åº¦æ€è€ƒæ¨¡å¼ï¼Œé«˜è´¨é‡


class ThinkingStatus(Enum):
    """æ€è€ƒçŠ¶æ€æšä¸¾"""
    IDLE = auto()       # ç©ºé—²
    THINKING = auto()   # æ€è€ƒä¸­
    COMPLETED = auto()  # å®Œæˆ
    ERROR = auto()      # é”™è¯¯


class LLMProvider(Enum):
    """LLMæä¾›å•†æšä¸¾"""
    OPENAI = auto()     # OpenAI
    ANTHROPIC = auto()  # Anthropic
    DEEPSEEK = auto()   # DeepSeek
    SILICONFLOW = auto() # SiliconFlow
    DOUBAO = auto()      # Doubao
    CUSTOM = auto()     # è‡ªå®šä¹‰API
    DUMMY = auto()      # æµ‹è¯•æ¨¡å¼


class MixedThinkingEngine:
    """æ··åˆæ€è€ƒå¼•æ“ï¼Œæ”¯æŒSiliconflowå’ŒDoubao APIè°ƒç”¨"""

    def __init__(
        self,
        fast_model_name: str = "doubao-seed-1-6-flash-250615",
        deep_model_name: str = "doubao-seed-1-6-thinking-250615",
        api_key: Optional[str] = None,
        api_base: Optional[str] = None,
        provider: LLMProvider = LLMProvider.SILICONFLOW,
        system_prompt: Optional[str] = None,
        debug: bool = False
    ):
        self.fast_model_name = fast_model_name
        self.deep_model_name = deep_model_name
        self.debug = debug
        self.provider = provider

        # æ ¹æ®æä¾›å•†è‡ªåŠ¨é…ç½®APIå‚æ•°
        if provider == LLMProvider.SILICONFLOW:
            self.api_key = api_key or os.environ.get("SILICONFLOW_API_KEY")
            self.api_base = api_base or "https://api.siliconflow.cn/v1"
            if not self.api_key:
                raise ValueError("è¯·è®¾ç½® SILICONFLOW_API_KEY ç¯å¢ƒå˜é‡æˆ–é€šè¿‡å‚æ•°æä¾›")
        elif provider == LLMProvider.DOUBAO:
            self.api_key = api_key or os.environ.get("ARK_API_KEY") or os.environ.get("VOLC_API_KEY")
            self.api_base = api_base or "https://ark.cn-beijing.volces.com/api/v3"
            if not self.api_key:
                raise ValueError("è¯·è®¾ç½® ARK_API_KEY æˆ– VOLC_API_KEY ç¯å¢ƒå˜é‡æˆ–é€šè¿‡å‚æ•°æä¾›")
        else:
            # å…¶ä»–æä¾›å•†çš„é…ç½®
            self.api_key = api_key
            self.api_base = api_base
            if not self.api_key:
                raise ValueError(f"è¯·ä¸º{provider.name}æä¾›APIå¯†é’¥")

        self.client = AsyncOpenAI(api_key=self.api_key, base_url=self.api_base)
        
        self.system_prompt = system_prompt or """ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ï¼Œä¸“é—¨è´Ÿè´£ååŠ©ç”¨æˆ·ä¸ç½‘é¡µè¡¨å•äº¤äº’ã€‚

é‡è¦æŒ‡å¼•ï¼š
1. ä½ ä¼šæ”¶åˆ°æ¥è‡ªComputer Agentçš„å®æ—¶é¡µé¢ä¿¡æ¯ï¼ŒåŒ…æ‹¬é¡µé¢æ ‡é¢˜ã€è¡¨å•æ•°é‡å’Œè¯¦ç»†çš„è¡¨å•å­—æ®µä¿¡æ¯
2. è¯·å§‹ç»ˆåŸºäºè¿™äº›çœŸå®çš„é¡µé¢ä¿¡æ¯ä¸ç”¨æˆ·æ²Ÿé€šï¼Œä¸è¦æåŠä¸å­˜åœ¨çš„é¡µé¢æˆ–è¡¨å•å­—æ®µ
3. å½“ç”¨æˆ·æä¾›è¡¨å•ä¿¡æ¯æ—¶ï¼Œè¯·æ ¹æ®å®é™…é¡µé¢çš„è¡¨å•å­—æ®µå¼•å¯¼ç”¨æˆ·å¡«å†™
4. å¿«æ€è€ƒé˜¶æ®µï¼šç»™å‡ºç®€çŸ­ã€è‡ªç„¶çš„å›åº”ï¼ŒåŸºäºçœŸå®è¡¨å•å­—æ®µ
5. æ·±åº¦æ€è€ƒé˜¶æ®µï¼šå¯ä»¥è¿›è¡Œæ›´è¯¦ç»†çš„åˆ†æï¼Œä½†å¿…é¡»åŸºäºå®é™…é¡µé¢å†…å®¹
6. ç»å¯¹ä¸è¦æåŠé¡µé¢ä¸Šä¸å­˜åœ¨çš„å­—æ®µï¼Œå¦‚"ä¸»é¢˜"ã€"æ¶ˆæ¯å†…å®¹"ç­‰ï¼Œé™¤éComputer Agentæ˜ç¡®æä¾›äº†è¿™äº›å­—æ®µä¿¡æ¯"""
        self.conversation_history = [{"role": "system", "content": self.system_prompt}]
        self.log(f"æ€è€ƒå¼•æ“åˆå§‹åŒ–å®Œæˆï¼Œæä¾›å•†: {provider.name}, API: {self.api_base}")
        self.log(f"å¿«æ€è€ƒæ¨¡å‹: {self.fast_model_name}, æ…¢æ€è€ƒæ¨¡å‹: {self.deep_model_name}")

    def log(self, message: str):
        if self.debug:
            print(f"[{time.strftime('%H:%M:%S')}][ThinkingEngine] {message}")

    def add_message(self, role: str, content: str):
        self.conversation_history.append({"role": role, "content": content})

    def reset_history(self):
        self.conversation_history = [{"role": "system", "content": self.system_prompt}]

    async def think(self, message_queue=None, user_text="") -> Tuple[str, str]:
        """åŒæ—¶æ‰§è¡Œå¿«æ€è€ƒå’Œæ·±åº¦æ€è€ƒï¼Œå¹¶åœ¨å¿«æ€è€ƒå®Œæˆåç«‹å³å¤„ç†è¡¨å•ä¿¡æ¯"""
        print("ğŸ¤” æ€è€ƒå¼•æ“å¼€å§‹å·¥ä½œ...")
        print(f"ğŸ’­ å¯¹è¯å†å²é•¿åº¦: {len(self.conversation_history)} æ¡æ¶ˆæ¯")
        
        messages = self.conversation_history
        
        # æ˜¾ç¤ºæœ€åå‡ æ¡æ¶ˆæ¯ç”¨äºè°ƒè¯•
        if messages:
            print("ğŸ“ æœ€è¿‘çš„å¯¹è¯:")
            for msg in messages[-3:]:  # æ˜¾ç¤ºæœ€å3æ¡æ¶ˆæ¯
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')[:50]
                print(f"   {role}: {content}...")
        
        print("ğŸš€ å¯åŠ¨å¿«æ€è€ƒå’Œæ·±åº¦æ€è€ƒ...")
        fast_task = asyncio.create_task(self._fast_think(messages))
        deep_task = asyncio.create_task(self._deep_think(messages))
        
        try:
            # ç­‰å¾…å¿«æ€è€ƒå®Œæˆ
            fast_response = await fast_task
            print(f"âš¡ å¿«æ€è€ƒå®Œæˆ: '{fast_response[:50]}...'")
            
            # å¿«æ€è€ƒå®Œæˆåç«‹å³è¿›è¡Œè¡¨å•ä¿¡æ¯æå–å’Œå‘é€
            if message_queue and user_text:
                await self._extract_and_send_form_data_fast(message_queue, user_text, fast_response)
            
            # ç­‰å¾…æ·±åº¦æ€è€ƒå®Œæˆ
            deep_response = await deep_task
            print(f"âœ… æ€è€ƒå®Œæˆ - å¿«é€Ÿ: {len(fast_response)}å­—ç¬¦, æ·±åº¦: {len(deep_response)}å­—ç¬¦")
            return fast_response, deep_response
        except Exception as e:
            print(f"âŒ æ€è€ƒè¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›åº”ã€‚", ""

    async def _fast_think(self, messages: List[Dict[str, str]]) -> str:
        """å¿«æ€è€ƒè·¯å¾„ - ä¼˜åŒ–ç”¨äºä½å»¶è¿Ÿå¿«é€Ÿå“åº”"""
        try:
            print(f"âš¡ å¯åŠ¨å¿«æ€è€ƒ (æ¨¡å‹: {self.fast_model_name})...")
            self.log(f"å¯åŠ¨å¿«æ€è€ƒ (æ¨¡å‹: {self.fast_model_name})...")
            response = await self.client.chat.completions.create(
                model=self.fast_model_name,
                messages=messages,
                stream=True,  # å¯ç”¨æµå¼å“åº”ä»¥æé«˜å“åº”é€Ÿåº¦
                max_tokens=150,  # é™åˆ¶tokenæ•°é‡ä»¥å‡å°‘å»¶è¿Ÿ
                temperature=0.7,  # é€‚ä¸­çš„åˆ›é€ æ€§
                timeout=10  # 10ç§’è¶…æ—¶
            )
            
            print("ğŸ”„ æ­£åœ¨æ¥æ”¶å¿«æ€è€ƒæµå¼å“åº”...")
            # å¤„ç†æµå¼å“åº”
            content = ""
            async for chunk in response:
                if chunk.choices[0].delta.content:
                    content += chunk.choices[0].delta.content
            
            print(f"âš¡ å¿«æ€è€ƒå®Œæˆ: '{content[:50]}...'")
            self.log(f"å¿«æ€è€ƒå®Œæˆ: {content}")
            return content.strip()
        except Exception as e:
            print(f"âŒ å¿«æ€è€ƒå‡ºé”™: {e}")
            self.log(f"å¿«æ€è€ƒå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return "å—¯..."

    async def _deep_think(self, messages: List[Dict[str, str]]) -> str:
        """æ·±åº¦æ€è€ƒè·¯å¾„ - ä¼˜åŒ–ç”¨äºå¤æ‚æ¨ç†å’Œä»»åŠ¡è§„åˆ’"""
        try:
            print(f"ğŸ§  å¯åŠ¨æ·±åº¦æ€è€ƒ (æ¨¡å‹: {self.deep_model_name})...")
            self.log(f"å¯åŠ¨æ·±åº¦æ€è€ƒ (æ¨¡å‹: {self.deep_model_name})...")
            
            # ä¸ºæ·±åº¦æ€è€ƒæ·»åŠ æ›´è¯¦ç»†çš„ç³»ç»Ÿæç¤º
            enhanced_messages = messages.copy()
            if enhanced_messages[0]["role"] == "system":
                enhanced_messages[0]["content"] += "\n\nè¯·è¿›è¡Œæ·±å…¥æ€è€ƒï¼Œè€ƒè™‘ä»¥ä¸‹è¦ç‚¹ï¼š\n1. ç†è§£ç”¨æˆ·çš„çœŸå®æ„å›¾\n2. åˆ†ææ‰€éœ€çš„å…·ä½“æ“ä½œæ­¥éª¤\n3. è€ƒè™‘å¯èƒ½çš„å¼‚å¸¸æƒ…å†µ\n4. æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›åº”"
            
            response = await self.client.chat.completions.create(
                model=self.deep_model_name,
                messages=enhanced_messages,
                stream=False,  # æ·±åº¦æ€è€ƒä¸éœ€è¦æµå¼å“åº”
                max_tokens=1000,  # å…è®¸æ›´é•¿çš„å›åº”
                temperature=0.3,  # è¾ƒä½çš„åˆ›é€ æ€§ï¼Œæé«˜å‡†ç¡®æ€§
                timeout=30  # 30ç§’è¶…æ—¶ï¼Œå…è®¸æ›´é•¿çš„æ€è€ƒæ—¶é—´
            )
            content = response.choices[0].message.content
            print(f"ğŸ§  æ·±åº¦æ€è€ƒå®Œæˆ: '{content[:50]}...'")
            self.log(f"æ·±åº¦æ€è€ƒå®Œæˆ: {content}")
            return content.strip()
        except Exception as e:
            print(f"âŒ æ·±åº¦æ€è€ƒå‡ºé”™: {e}")
            self.log(f"æ·±åº¦æ€è€ƒå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return "è®©æˆ‘æƒ³æƒ³...å•Šï¼ŒæŠ±æ­‰ï¼Œæˆ‘åˆšåˆšèµ°ç¥äº†ã€‚"

    async def generate_filler(self) -> str:
        """ç”Ÿæˆå¡«å……è¯­"""
        try:
            response = await self.client.chat.completions.create(
                model=self.fast_model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¯¹è¯å¡«å……è¯­ç”ŸæˆåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": "ç”Ÿæˆä¸€ä¸ªç®€çŸ­ã€è‡ªç„¶ã€è¡¨ç¤ºæ­£åœ¨æ€è€ƒçš„å¡«å……è¯­ï¼Œä¾‹å¦‚'å—¯...'ã€'è®©æˆ‘æƒ³æƒ³çœ‹'ç­‰ã€‚"}
                ],
                max_tokens=10,
                stream=False
            )
            filler = response.choices[0].message.content.strip(' "\'')
            return filler
        except Exception as e:
            self.log(f"å¡«å……è¯­ç”Ÿæˆå‡ºé”™: {e}")
            return "å—¯..."

    async def _extract_and_send_form_data_fast(self, message_queue, user_text: str, fast_response: str):
        """å¿«æ€è€ƒå®Œæˆåç«‹å³æå–è¡¨å•æ•°æ®å¹¶å‘é€ç»™Computer Agent"""
        try:
            import uuid
            print("ğŸš€ å¿«æ€è€ƒå®Œæˆï¼Œç«‹å³æ£€æŸ¥è¡¨å•ä¿¡æ¯...")
            
            # æ‰©å±•çš„è¡¨å•ç›¸å…³å…³é”®è¯
            form_keywords = ["å¡«å†™", "è¡¨å•", "è¾“å…¥", "åå­—", "å§“å", "é‚®ç®±", "email", "ç”µè¯", "æ‰‹æœº", "åœ°å€", "æäº¤", "å¡«è¡¨", "å¼€å§‹å¡«"]
            has_form_keyword = any(keyword in user_text for keyword in form_keywords)
            
            # ä½¿ç”¨æ™ºèƒ½ä¿¡æ¯æå–ï¼ˆç®€åŒ–ç‰ˆï¼Œé¿å…æåŠä¸å­˜åœ¨çš„å­—æ®µï¼‰
            extracted_data = self._extract_basic_form_data_from_text(user_text)
            
            if has_form_keyword or extracted_data:
                print(f"ğŸ“ å¿«æ€è€ƒé˜¶æ®µæ£€æµ‹åˆ°è¡¨å•ç›¸å…³æ“ä½œæˆ–æ•°æ®: {extracted_data}")
                
                # ç«‹å³å‘é€æ¶ˆæ¯ç»™Computer Agent
                from dual_agent.common.messaging import A2AMessage, MessageType, MessageSource
                
                message = A2AMessage(
                    source=MessageSource.PHONE,
                    type=MessageType.ACTION,
                    task_id=str(uuid.uuid4()),
                    content={
                        "action": "fill_form",
                        "user_input": user_text,
                        "ai_fast_response": fast_response,  # ä½¿ç”¨å¿«æ€è€ƒçš„å›åº”
                        "extracted_data": extracted_data,
                        "immediate": True,  # æ ‡è®°ä¸ºç«‹å³æ‰§è¡Œ
                        "from_fast_thinking": True  # æ ‡è®°æ¥è‡ªå¿«æ€è€ƒ
                    }
                )
                
                await message_queue.send_to_computer(message)
                print(f"âš¡ å·²ä»å¿«æ€è€ƒé˜¶æ®µå‘é€è¡¨å•æ“ä½œæŒ‡ä»¤ç»™Computer Agent")
                self.log(f"âš¡ Sent fast form instruction to Computer Agent: {user_text}")
                
                # å¦‚æœæå–åˆ°äº†å…·ä½“æ•°æ®ï¼Œè®°å½•ç¡®è®¤ä¿¡æ¯
                if extracted_data:
                    data_summary = ", ".join([f"{k}: {v}" for k, v in extracted_data.items()])
                    print(f"ğŸ“¢ å¿«é€Ÿç¡®è®¤: æ­£åœ¨å¤„ç† {data_summary}")
                
        except Exception as e:
            self.log(f"å¿«æ€è€ƒé˜¶æ®µå‘é€Computer AgentæŒ‡ä»¤æ—¶å‡ºé”™: {e}")
            print(f"âŒ å¿«æ€è€ƒé˜¶æ®µå‘é€Computer AgentæŒ‡ä»¤æ—¶å‡ºé”™: {e}")
    
    def _extract_basic_form_data_from_text(self, text):
        """ä»æ–‡æœ¬ä¸­æå–åŸºç¡€è¡¨å•æ•°æ®ï¼ˆé¿å…æåŠä¸å­˜åœ¨çš„å­—æ®µï¼‰"""
        import re
        
        extracted = {}
        text_lower = text.lower()
        
        print(f"ğŸ” å¿«æ€è€ƒé˜¶æ®µæå–è¡¨å•æ•°æ®ï¼Œè¾“å…¥æ–‡æœ¬: '{text}'")
        
        # å§“åæå– - æ›´çµæ´»çš„æ¨¡å¼
        name_patterns = [
            r'(?:æˆ‘å«|æˆ‘çš„åå­—æ˜¯|åå­—æ˜¯|å§“åæ˜¯|æˆ‘æ˜¯)([^ï¼Œ,ã€‚\s]{1,10})',
            r'(?:å«|åå­—)([^ï¼Œ,ã€‚\s]{1,10})',
            r'(?:å§“å|åå­—)(?:å¡«å†™|å¡«å…¥|æ˜¯|ä¸º)([^ï¼Œ,ã€‚\s]{1,10})',  # æ–°å¢ï¼šå§“åå¡«å†™å¼ ä¸‰
            r'(?:å¡«å†™|å¡«å…¥)(?:å§“å|åå­—)([^ï¼Œ,ã€‚\s]{1,10})',     # æ–°å¢ï¼šå¡«å†™å§“åå¼ ä¸‰
            r'([^ï¼Œ,ã€‚\s]{1,10})(?:æ˜¯æˆ‘çš„åå­—|æ˜¯æˆ‘çš„å§“å)',      # æ–°å¢ï¼šå¼ ä¸‰æ˜¯æˆ‘çš„åå­—
            r'å§“å([^ï¼Œ,ã€‚\s]{1,10})',                         # æ–°å¢ï¼šå§“åå¼ ä¸‰
            r'åå­—([^ï¼Œ,ã€‚\s]{1,10})',                         # æ–°å¢ï¼šåå­—å¼ ä¸‰
        ]
        for i, pattern in enumerate(name_patterns):
            print(f"   å°è¯•å§“åæ¨¡å¼ {i+1}: {pattern}")
            matches = re.findall(pattern, text)
            if matches:
                name = matches[0].strip()
                if len(name) <= 10 and name:  # åˆç†çš„åå­—é•¿åº¦
                    extracted["name"] = name
                    extracted["custname"] = name
                    print(f"   âœ… åŒ¹é…æˆåŠŸï¼Œæå–å§“å: {name}")
                break
            else:
                print(f"   âŒ æ¨¡å¼ä¸åŒ¹é…")
        
        # é‚®ç®±æå–
        print(f"   ğŸ“§ å¼€å§‹é‚®ç®±æå–...")
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        emails = re.findall(email_pattern, text)
        if emails:
            extracted["email"] = emails[0]
            extracted["custemail"] = emails[0]
            print(f"   âœ… æå–é‚®ç®±: {emails[0]}")
        else:
            print(f"   âŒ æœªæ‰¾åˆ°é‚®ç®±æ ¼å¼")
        
        # ç”µè¯å·ç æå–
        print(f"   ğŸ” å¼€å§‹ç”µè¯å·ç æå–...")
        phone_patterns = [
            r'\b(?:\+?86[-.\\s]?)?1[3-9]\d{9}\b',  # ä¸­å›½æ‰‹æœºå·
            r'\b(?:\+?1[-.\\s]?)?\(?[0-9]{3}\)?[-.\\s]?[0-9]{3}[-.\\s]?[0-9]{4}\b',  # ç¾å›½ç”µè¯
            r'(?:ç”µè¯|æ‰‹æœº|è”ç³»æ–¹å¼)(?:æ˜¯|ä¸º|å·ç æ˜¯)([0-9]{4,15})',  # æ–°å¢ï¼šç”µè¯æ˜¯123456
            r'(?:å¡«å†™|å¡«å…¥)(?:ç”µè¯|æ‰‹æœº)([0-9]{4,15})',          # æ–°å¢ï¼šå¡«å†™ç”µè¯123456
            r'([0-9]{6,15})(?:æ˜¯æˆ‘çš„ç”µè¯|æ˜¯æˆ‘çš„æ‰‹æœº)',            # æ–°å¢ï¼š123456æ˜¯æˆ‘çš„ç”µè¯
            r'(?:telephone|phone|tel)\s*(?:number)?\s*([0-9]{4,15})',  # æ–°å¢ï¼štelephone number1234567890
            r'\b([0-9]{6,15})\b'  # æœ€åå°è¯•ï¼šä»»ä½•6-15ä½æ•°å­—ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
        ]
        for i, pattern in enumerate(phone_patterns):
            print(f"   å°è¯•ç”µè¯æ¨¡å¼ {i+1}: {pattern}")
            phones = re.findall(pattern, text, re.IGNORECASE)
            if phones:
                phone = re.sub(r'[-.\\s()]+', '', phones[0])
                extracted["phone"] = phone
                extracted["custtel"] = phone
                print(f"   âœ… æå–ç”µè¯: {phone}")
                break
            else:
                print(f"   âŒ ç”µè¯æ¨¡å¼ä¸åŒ¹é…")
        
        # è¯„è®º/æ¶ˆæ¯å†…å®¹æå–ï¼ˆä»…é™æ˜ç¡®ç›¸å…³çš„å­—æ®µï¼‰
        print(f"   ğŸ’¬ å¼€å§‹æ¶ˆæ¯å†…å®¹æå–...")
        message_patterns = [
            r'(?:è¯„è®ºæ˜¯|ç•™è¨€æ˜¯|æ¶ˆæ¯å†…å®¹æ˜¯)([^ã€‚ï¼Œ,]{5,100})',
            r'(?:è¯„è®º|ç•™è¨€)[:ï¼š]([^ã€‚ï¼Œ,]{5,100})',
        ]
        for i, pattern in enumerate(message_patterns):
            print(f"   å°è¯•æ¶ˆæ¯æ¨¡å¼ {i+1}: {pattern}")
            matches = re.findall(pattern, text)
            if matches:
                message = matches[0].strip()
                if message:
                    extracted["message"] = message
                    extracted["comments"] = message
                    print(f"   âœ… æå–æ¶ˆæ¯: {message}")
                break
            else:
                print(f"   âŒ æ¶ˆæ¯æ¨¡å¼ä¸åŒ¹é…")
        
        if extracted:
            print(f"ğŸ“Š å¿«æ€è€ƒé˜¶æ®µæå–åˆ°åŸºç¡€è¡¨å•æ•°æ®: {extracted}")
        else:
            print(f"âš ï¸ å¿«æ€è€ƒé˜¶æ®µæœªæå–åˆ°ä»»ä½•è¡¨å•æ•°æ®")
        
        return extracted 